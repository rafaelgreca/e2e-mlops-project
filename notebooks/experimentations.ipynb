{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from mlflow.models import infer_signature\n",
    "from pprint import pprint\n",
    "from typing import Union, Dict, List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import boto3\n",
    "import joblib\n",
    "import os\n",
    "import math\n",
    "import mlflow\n",
    "import optuna\n",
    "import warnings\n",
    "import shutil\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_yaml_file(path, file):\n",
    "    # reading credentials files\n",
    "    with open(f\"{os.path.join(path, file)}\") as f:\n",
    "        try:\n",
    "            content = yaml.safe_load(f)\n",
    "        except yaml.YAMLError as e:\n",
    "            raise e\n",
    "    \n",
    "    return content\n",
    "\n",
    "CONFIG_PATH = os.path.join(\"..\", \"src\", \"config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"VERSION\", \"r\") as f:\n",
    "    CODE_VERSION = f.readline().strip()\n",
    "\n",
    "credentials_config = read_yaml_file(\n",
    "    path=CONFIG_PATH,\n",
    "    file=\"credentials.yaml\"\n",
    ")\n",
    "\n",
    "general_settings = read_yaml_file(\n",
    "    path=CONFIG_PATH,\n",
    "    file=\"settings.yaml\"\n",
    ")\n",
    "\n",
    "if credentials_config[\"EC2\"] != \"YOUR_EC2_INSTANCE_URL\":\n",
    "    mlflow.set_tracking_uri(f\"http://{credentials_config['EC2']}:5000\") \n",
    "else:\n",
    "    mlflow.set_tracking_uri(f\"http://mlflow:5000\") \n",
    "\n",
    "print(f\"Tracking Server URI: '{mlflow.get_tracking_uri()}'\")\n",
    "\n",
    "SEED = 42\n",
    "ARTIFACTS_OUTPUT_PATH = general_settings[\"ARTIFACTS_PATH\"]\n",
    "FEATURES_OUTPUT_PATH = general_settings[\"FEATURES_PATH\"]\n",
    "RAW_FILE_PATH = os.path.join(general_settings[\"DATA_PATH\"], general_settings[\"RAW_FILE_NAME\"])\n",
    "PROCESSED_RAW_FILE = \"Preprocessed_\" + general_settings[\"RAW_FILE_NAME\"]\n",
    "PROCESSED_RAW_FILE_PATH = os.path.join(general_settings[\"DATA_PATH\"], PROCESSED_RAW_FILE)\n",
    "FEATURE_SELECTION_EXPERIMENT_NAME = \"feature-selection-experimentation\"\n",
    "HYPERPARAMETER_TUNING_EXPERIMENT_NAME = \"hyperparameters-tuning-experimentation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading the preprocessed dataset from the aws s3 bucket\n",
    "if credentials_config[\"S3\"] != \"YOUR_S3_BUCKET_URL\":\n",
    "    # configuring AWS credentials\n",
    "    os.environ[\"AWS_ACCESS_KEY_ID\"] = credentials_config[\"AWS_ACCESS_KEY\"]\n",
    "    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = credentials_config[\"AWS_SECRET_KEY\"]\n",
    "\n",
    "    # downloading preprocessed dataset\n",
    "    s3 = boto3.client(\n",
    "        \"s3\",\n",
    "        aws_access_key_id=credentials_config[\"AWS_ACCESS_KEY\"],\n",
    "        aws_secret_access_key=credentials_config[\"AWS_SECRET_KEY\"]\n",
    "    )\n",
    "    s3.download_file(\n",
    "        credentials_config[\"S3\"],\n",
    "        PROCESSED_RAW_FILE,\n",
    "        PROCESSED_RAW_FILE_PATH\n",
    "    )\n",
    "\n",
    "    # downloading artifacts from the aws s3 bucket\n",
    "    !aws s3 cp --recursive s3://{credentials_config[\"S3\"]}/artifacts {ARTIFACTS_OUTPUT_PATH}\n",
    "\n",
    "    # downloading models from the aws s3 bucket\n",
    "    !aws s3 cp --recursive s3://{credentials_config[\"S3\"]}/features {FEATURES_OUTPUT_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading features\n",
    "X_train = joblib.load(os.path.join(FEATURES_OUTPUT_PATH, \"X_train.pkl\"))\n",
    "y_train = joblib.load(os.path.join(FEATURES_OUTPUT_PATH, \"y_train.pkl\"))\n",
    "\n",
    "X_valid = joblib.load(os.path.join(FEATURES_OUTPUT_PATH, \"X_valid.pkl\"))\n",
    "y_valid = joblib.load(os.path.join(FEATURES_OUTPUT_PATH, \"y_valid.pkl\"))\n",
    "\n",
    "# loading artifacts\n",
    "sc = joblib.load(os.path.join(ARTIFACTS_OUTPUT_PATH, \"features_sc.pkl\"))\n",
    "ohe = joblib.load(os.path.join(ARTIFACTS_OUTPUT_PATH, \"features_ohe.pkl\"))\n",
    "ohe_label = joblib.load(os.path.join(ARTIFACTS_OUTPUT_PATH, \"label_ohe.pkl\"))\n",
    "\n",
    "# loading feature columns\n",
    "temp_df = pd.read_csv(PROCESSED_RAW_FILE_PATH, sep=\",\")\n",
    "FEATURES_NAME = temp_df.columns.tolist()\n",
    "del temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the baseline models\n",
    "dt = DecisionTreeClassifier(random_state=SEED)\n",
    "rf = RandomForestClassifier(random_state=SEED, verbose=0, n_jobs=-1)\n",
    "xg = XGBClassifier(random_state=SEED, n_jobs=-1)\n",
    "lg = LGBMClassifier(random_state=SEED, verbose=-1, objective=\"multiclass\")\n",
    "cb = CatBoostClassifier(random_seed=SEED, verbose=0, allow_writing_files=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_feature_selection(\n",
    "    model: Union[DecisionTreeClassifier, RandomForestClassifier, XGBClassifier, LGBMClassifier, CatBoostClassifier],\n",
    "    number_features: int,\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.array,\n",
    "    X_valid: np.ndarray,\n",
    "    y_valid: np.array,\n",
    ") -> Dict:\n",
    "    # initializing and fitting the sfs class\n",
    "    sfs = SequentialFeatureSelector(\n",
    "        model,\n",
    "        n_features_to_select=number_features,\n",
    "        cv=3\n",
    "    )\n",
    "    sfs.fit(X=X_train, y=y_train)\n",
    "\n",
    "    # getting the indexes of the best features\n",
    "    selected_features_indexes = np.argwhere(sfs.get_support()).reshape(-1)\n",
    "\n",
    "    reduced_X_train = sfs.transform(X_train)\n",
    "    reduced_X_valid = sfs.transform(X_valid)\n",
    "\n",
    "    # training the model\n",
    "    model.fit(reduced_X_train, y_train)\n",
    "\n",
    "    # calculating the training f1 score\n",
    "    predicted_y_train = model.predict(reduced_X_train)\n",
    "    train_f1 = f1_score(\n",
    "        y_true=y_train,\n",
    "        y_pred=predicted_y_train,\n",
    "        average=\"weighted\"\n",
    "    )\n",
    "    \n",
    "    # calculating the validation f1 score\n",
    "    predicted_y_valid = model.predict(reduced_X_valid)\n",
    "    valid_f1 = f1_score(\n",
    "        y_true=y_valid,\n",
    "        y_pred=predicted_y_valid,\n",
    "        average=\"weighted\"\n",
    "    )\n",
    "\n",
    "    # inferring the signature of the trained model\n",
    "    signature = infer_signature(\n",
    "        model_input=reduced_X_train,\n",
    "        model_output=predicted_y_train\n",
    "    )\n",
    "    \n",
    "    # saving the metrics and artifacts that we want to log in mlflow\n",
    "    selected_features_names = list(map(lambda i: FEATURES_NAME[i], selected_features_indexes.tolist()))\n",
    "\n",
    "    results = {\n",
    "        \"train_f1\": train_f1,\n",
    "        \"valid_f1\": valid_f1,\n",
    "        \"features\": selected_features_names,\n",
    "        \"model\": model,\n",
    "        \"model_signature\": signature\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "def set_configurations_mlflow(\n",
    "    model: Union[DecisionTreeClassifier, RandomForestClassifier, XGBClassifier, LGBMClassifier, CatBoostClassifier],\n",
    "    y_train: np.array,\n",
    "    y_valid: np.array,\n",
    ") -> Tuple[np.array, np.array, str, str]:\n",
    "    # reshaping the target values (if needed) and setting the run name and which\n",
    "    # flavor is being used for each machine learning model\n",
    "    if isinstance(model, DecisionTreeClassifier):\n",
    "        y_train = np.argmax(y_train, axis=1)\n",
    "        y_valid = np.argmax(y_valid, axis=1)\n",
    "        run_name = \"decision_tree\"\n",
    "        flavor = \"sklearn\"\n",
    "    \n",
    "    if isinstance(model, RandomForestClassifier):\n",
    "        run_name = \"random_forest\"\n",
    "        flavor = \"sklearn\"\n",
    "    \n",
    "    if isinstance(model, XGBClassifier):\n",
    "        run_name = \"xgboost\"\n",
    "        flavor = \"xgboost\"\n",
    "    \n",
    "    if isinstance(model, LGBMClassifier):\n",
    "        y_train = np.argmax(y_train, axis=1)\n",
    "        y_valid = np.argmax(y_valid, axis=1)\n",
    "        run_name = \"lightgbm\"\n",
    "        flavor = \"lightgbm\"\n",
    "    \n",
    "    if isinstance(model, CatBoostClassifier):\n",
    "        y_train = np.argmax(y_train, axis=1)\n",
    "        y_valid = np.argmax(y_valid, axis=1)\n",
    "        run_name = \"catboost\"\n",
    "        flavor = \"catboost\"\n",
    "    \n",
    "    # disabling some options of the current flavor's autolog\n",
    "    if flavor == \"sklearn\":\n",
    "        mlflow.sklearn.autolog(\n",
    "            log_models=False,\n",
    "            log_post_training_metrics=False,\n",
    "            log_model_signatures=False,\n",
    "            log_input_examples=True,\n",
    "            log_datasets=False,\n",
    "            silent=True,\n",
    "            disable=True\n",
    "        )\n",
    "    elif flavor == \"xgboost\":\n",
    "        mlflow.xgboost.autolog(\n",
    "            log_models=False,\n",
    "            log_model_signatures=False,\n",
    "            log_input_examples=True,\n",
    "            log_datasets=False,\n",
    "            silent=True,\n",
    "            disable=True\n",
    "        )\n",
    "    elif flavor == \"lightgbm\":\n",
    "        mlflow.lightgbm.autolog(\n",
    "            log_models=False,\n",
    "            log_model_signatures=False,\n",
    "            log_input_examples=True,\n",
    "            log_datasets=False,\n",
    "            silent=True,\n",
    "            disable=True\n",
    "        )\n",
    "    elif flavor == \"catboost\":\n",
    "        # there is no autolog implemented for catboost\n",
    "        pass\n",
    "\n",
    "    return y_train, y_valid, run_name, flavor\n",
    "\n",
    "def run_feature_selection_experiment(\n",
    "    models: List,\n",
    "    min_features: int,\n",
    "    max_features: int,\n",
    "    experiment_id: str\n",
    ") -> None:\n",
    "    for model in models:\n",
    "        # reshaping the target values (if needed) and setting some mlflow's configuration\n",
    "        new_y_train, new_y_valid, run_name, flavor = set_configurations_mlflow(\n",
    "            model=model,\n",
    "            y_train=y_train,\n",
    "            y_valid=y_valid\n",
    "        )\n",
    "        \n",
    "        # starting a new run for the current model\n",
    "        with mlflow.start_run(experiment_id=experiment_id, run_name=run_name):\n",
    "            pprint(f\"Starting the run for the {run_name} model!\\n\")\n",
    "\n",
    "            for i, n_features in enumerate(range(min_features, max_features + 1)):\n",
    "                # creating a nested run inside the model's main run\n",
    "                with mlflow.start_run(\n",
    "                    experiment_id=experiment_id,\n",
    "                    run_name=f\"{run_name}_experiment_{i}\",\n",
    "                    nested=True\n",
    "                ):\n",
    "                    # running the feature selection main function\n",
    "                    results = apply_feature_selection(\n",
    "                        model=model,\n",
    "                        number_features=n_features,\n",
    "                        X_train=X_train,\n",
    "                        y_train=new_y_train,\n",
    "                        X_valid=X_valid,\n",
    "                        y_valid=new_y_valid\n",
    "                    )\n",
    "\n",
    "                    # logging the trained model\n",
    "                    if flavor == \"sklearn\":\n",
    "                        mlflow.sklearn.log_model(\n",
    "                            results[\"model\"],\n",
    "                            run_name,\n",
    "                            signature=results[\"model_signature\"]\n",
    "                        )\n",
    "                        # logging the model\"s default parameters\n",
    "                        mlflow.log_params(results[\"model\"].get_params(deep=True))\n",
    "                    elif flavor == \"xgboost\":\n",
    "                        mlflow.xgboost.log_model(\n",
    "                            results[\"model\"],\n",
    "                            run_name,\n",
    "                            signature=results[\"model_signature\"]\n",
    "                        )\n",
    "                        # logging the model's default parameters\n",
    "                        mlflow.log_params(results[\"model\"].get_params(deep=True))\n",
    "                    elif flavor == \"lightgbm\":\n",
    "                        mlflow.lightgbm.log_model(\n",
    "                            results[\"model\"],\n",
    "                            run_name,\n",
    "                            signature=results[\"model_signature\"]\n",
    "                        )\n",
    "                        # logging the model's default parameters\n",
    "                        mlflow.log_params(results[\"model\"].get_params())\n",
    "                    elif flavor == \"catboost\":\n",
    "                        mlflow.catboost.log_model(\n",
    "                            results[\"model\"],\n",
    "                            run_name,\n",
    "                            signature=results[\"model_signature\"]\n",
    "                        )\n",
    "                        # logging the model's default parameters\n",
    "                        mlflow.log_params(results[\"model\"].get_all_params())\n",
    "\n",
    "                    # logging the training and validation scores\n",
    "                    mlflow.log_metric(\"train_f1\", results[\"train_f1\"])\n",
    "                    mlflow.log_metric(\"valid_f1\", results[\"valid_f1\"])\n",
    "\n",
    "                    # logging the artifacts (original dataset, features, and encoders objects)\n",
    "                    mlflow.log_artifact(PROCESSED_RAW_FILE_PATH)\n",
    "                    mlflow.log_artifact(ARTIFACTS_OUTPUT_PATH)\n",
    "                    mlflow.log_artifact(FEATURES_OUTPUT_PATH)\n",
    "\n",
    "                    # logging the indexes of the best features\n",
    "                    mlflow.log_param(\"features\", results[\"features\"])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [dt, rf, xg, lg]\n",
    "min_features = math.floor(X_train.shape[1] * 0.2)\n",
    "max_features = math.floor(X_train.shape[1] * 0.5)\n",
    "\n",
    "# creating a new mlflow's experiment\n",
    "experiment_id = mlflow.create_experiment(\n",
    "    name=FEATURE_SELECTION_EXPERIMENT_NAME,\n",
    "    tags={\"version\": \"v2\", \"code_version\": CODE_VERSION}\n",
    ")\n",
    "\n",
    "# running the feature selection experiments\n",
    "run_feature_selection_experiment(\n",
    "    models=models,\n",
    "    min_features=min_features,\n",
    "    max_features=max_features,\n",
    "    experiment_id=experiment_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Objective:\n",
    "    def __init__(\n",
    "        self,\n",
    "        run_name: str,\n",
    "        experiment_id: str,\n",
    "        X_train: np.ndarray,\n",
    "        y_train: np.array,\n",
    "        X_valid: np.ndarray,\n",
    "        y_valid: np.array,\n",
    "        indexes: List\n",
    "    ) -> None:\n",
    "        self.run_name = run_name\n",
    "        self.experiment_id = experiment_id\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_valid = X_valid\n",
    "        self.y_valid = y_valid\n",
    "        self.indexes_name = indexes\n",
    "        self.indexes = [FEATURES_NAME.index(i) for i in indexes]\n",
    "\n",
    "        if self.run_name in [\"decision_tree\", \"lightgbm\", \"catboost\"]:\n",
    "            self.y_train = np.argmax(self.y_train, axis=1)\n",
    "            self.y_valid = np.argmax(self.y_valid, axis=1)\n",
    "        \n",
    "        self.X_train = self.X_train[:, self.indexes]\n",
    "        self.X_valid = self.X_valid[:, self.indexes]\n",
    "    \n",
    "    def __call__(\n",
    "        self,\n",
    "        trial: optuna.trial.Trial\n",
    "    ) -> float:\n",
    "        with mlflow.start_run(experiment_id=self.experiment_id, nested=True):\n",
    "            if self.run_name == \"decision_tree\":\n",
    "                params = {\n",
    "                    \"max_depth\": trial.suggest_int(\"max_depth\", 2, 32, step=2),\n",
    "                    \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 8, step=1),\n",
    "                    \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 6, step=1),\n",
    "                    \"min_weight_fraction_leaf\": trial.suggest_float(\"min_weight_fraction_leaf\", 0, 0.5, step=0.1),\n",
    "                    \"max_leaf_nodes\": trial.suggest_int(\"max_leaf_nodes\", 2, 16, step=2),\n",
    "                    \"random_state\": SEED\n",
    "                }\n",
    "                model = DecisionTreeClassifier(**params)\n",
    "            \n",
    "            if self.run_name == \"random_forest\":\n",
    "                params = {\n",
    "                    \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "                    \"max_depth\": trial.suggest_int(\"max_depth\", 10, 50),\n",
    "                    \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 32),\n",
    "                    \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 32),\n",
    "                    \"random_state\": SEED,\n",
    "                    \"n_jobs\": -1,\n",
    "                }\n",
    "                model = RandomForestClassifier(**params)\n",
    "            \n",
    "            if self.run_name == \"xgboost\":\n",
    "                params = {\n",
    "                    \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"]),\n",
    "                    \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
    "                    \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
    "                    \"random_state\": SEED,\n",
    "                    \"n_jobs\": -1,\n",
    "                }\n",
    "                model = XGBClassifier(**params)\n",
    "            \n",
    "            if self.run_name == \"lightgbm\":\n",
    "                params = {\n",
    "                    \"objective\": \"multiclass\",\n",
    "                    \"verbosity\": -1,\n",
    "                    \"random_state\": SEED,\n",
    "                    \"n_jobs\": -1,\n",
    "                    \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "                    \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "                    \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "                    \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "                    \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "                    \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "                    \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "                }\n",
    "                model = LGBMClassifier(**params)\n",
    "            \n",
    "            if self.run_name == \"catboost\":\n",
    "                params = {\n",
    "                    \"random_seed\": SEED,\n",
    "                    \"verbose\": 0,\n",
    "                    \"allow_writing_files\": False,\n",
    "                    \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1),\n",
    "                    \"depth\": trial.suggest_int(\"depth\", 1, 12),\n",
    "                    \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
    "                    \"bootstrap_type\": trial.suggest_categorical(\n",
    "                        \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]\n",
    "                    )\n",
    "                }\n",
    "                model = CatBoostClassifier(**params)\n",
    "            \n",
    "            model.fit(X=self.X_train, y=self.y_train)\n",
    "\n",
    "            # calculating the training f1 score\n",
    "            train_prediction = model.predict(self.X_train)\n",
    "            train_f1 = f1_score(\n",
    "                y_true=self.y_train,\n",
    "                y_pred=train_prediction,\n",
    "                average=\"weighted\"\n",
    "            )\n",
    "\n",
    "            # calculating the validation f1 score\n",
    "            valid_prediction = model.predict(self.X_valid)\n",
    "            valid_f1 = f1_score(\n",
    "                y_true=self.y_valid,\n",
    "                y_pred=valid_prediction,\n",
    "                average=\"weighted\"\n",
    "            )\n",
    "\n",
    "            # logging the training and validation scores\n",
    "            mlflow.log_metric(\"train_f1\", train_f1)\n",
    "            mlflow.log_metric(\"valid_f1\", valid_f1)\n",
    "\n",
    "            # inferring the signature of the trained model\n",
    "            signature = infer_signature(\n",
    "                model_input=self.X_train,\n",
    "                model_output=train_prediction\n",
    "            )\n",
    "\n",
    "            # saving the trained model\n",
    "            if self.run_name in [\"decision_tree\", \"random_forest\"]:\n",
    "                # sklearn flavor\n",
    "                mlflow.sklearn.log_model(\n",
    "                    model,\n",
    "                    self.run_name,\n",
    "                    signature=signature\n",
    "                )\n",
    "                # logging the model\"s default parameters\n",
    "                mlflow.log_params(model.get_params(deep=True))\n",
    "            elif self.run_name == \"xgboost\":\n",
    "                mlflow.xgboost.log_model(\n",
    "                    model,\n",
    "                    self.run_name,\n",
    "                    signature=signature\n",
    "                )\n",
    "                # logging the model's default parameters\n",
    "                mlflow.log_params(model.get_params())\n",
    "            elif self.run_name == \"lightgbm\":\n",
    "                mlflow.lightgbm.log_model(\n",
    "                    model,\n",
    "                    self.run_name,\n",
    "                    signature=signature\n",
    "                )\n",
    "                # logging the model's default parameters\n",
    "                mlflow.log_params(model.get_params())\n",
    "            elif self.run_name == \"catboost\":\n",
    "                mlflow.catboost.log_model(\n",
    "                    model,\n",
    "                    self.run_name,\n",
    "                    signature=signature\n",
    "                )\n",
    "                # logging the model's default parameters\n",
    "                mlflow.log_params(model.get_all_params())\n",
    "\n",
    "        return valid_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new mlflow's experiment\n",
    "hpt_experiment_id = mlflow.create_experiment(\n",
    "    name=HYPERPARAMETER_TUNING_EXPERIMENT_NAME,\n",
    "    tags={\"version\": \"v2\", \"code_version\": CODE_VERSION}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_run_name = \"decision_tree\"\n",
    "dt_features_indexes = ['Gender_x0_Male', 'Age_x0_q2', 'Age_x0_q4', 'CAEC_x0_no', 'SCC_x0_yes', 'MTRANS_x0_Motorbike', 'Weight', 'BMI', 'BSA', 'IBW', 'diff_W_IBW']\n",
    "\n",
    "with mlflow.start_run(experiment_id=hpt_experiment_id, run_name=dt_run_name):\n",
    "    objective = Objective(\n",
    "        run_name=dt_run_name,\n",
    "        experiment_id=hpt_experiment_id,\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_valid=X_valid,\n",
    "        y_valid=y_valid,\n",
    "        indexes=dt_features_indexes\n",
    "    )\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_run_name = \"random_forest\"\n",
    "rf_features_indexes = ['Gender_x0_Male', 'Age_x0_q4', 'family_history_with_overweight_x0_yes', 'FAVC_x0_yes', 'CAEC_x0_Frequently', 'CAEC_x0_no', 'SCC_x0_yes', 'MTRANS_x0_Public_Transportation', 'MTRANS_x0_Walking', 'HH_x0_good', 'Weight', 'FCVC', 'NCP', 'CH2O', 'TUE', 'BMI', 'IBW', 'BMR']\n",
    "\n",
    "with mlflow.start_run(experiment_id=hpt_experiment_id, run_name=rf_run_name):\n",
    "    objective = Objective(\n",
    "        run_name=rf_run_name,\n",
    "        experiment_id=hpt_experiment_id,\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_valid=X_valid,\n",
    "        y_valid=y_valid,\n",
    "        indexes=rf_features_indexes\n",
    "    )\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_run_name = \"xgboost\"\n",
    "xg_features_indexes = ['Gender_x0_Male', 'Age_x0_q2', 'Age_x0_q3', 'Age_x0_q4', 'family_history_with_overweight_x0_yes', 'FAVC_x0_yes', 'CAEC_x0_no', 'SCC_x0_yes', 'CALC_x0_no', 'MTRANS_x0_Bike', 'MTRANS_x0_Walking', 'SWC_x0_1', 'IS_x0_1', 'Weight', 'FCVC', 'NCP', 'FAF', 'BMI']\n",
    "\n",
    "with mlflow.start_run(experiment_id=hpt_experiment_id, run_name=xgb_run_name):\n",
    "    objective = Objective(\n",
    "        run_name=xgb_run_name,\n",
    "        experiment_id=hpt_experiment_id,\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_valid=X_valid,\n",
    "        y_valid=y_valid,\n",
    "        indexes=xg_features_indexes\n",
    "    )\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_run_name = \"lightgbm\"\n",
    "lg_features_indexes = \t['Gender_x0_Male', 'Age_x0_q3', 'Age_x0_q4', 'FAVC_x0_yes', 'CAEC_x0_Frequently', 'SCC_x0_yes', 'CALC_x0_no', 'EVEMM_x0_1', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE', 'BMI', 'PAL', 'IBW']\n",
    "\n",
    "with mlflow.start_run(experiment_id=hpt_experiment_id, run_name=lg_run_name):\n",
    "    objective = Objective(\n",
    "        run_name=lg_run_name,\n",
    "        experiment_id=hpt_experiment_id,\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_valid=X_valid,\n",
    "        y_valid=y_valid,\n",
    "        indexes=lg_features_indexes\n",
    "    )\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_run_name = \"catboost\"\n",
    "cb_features_indexes = [3, 14, 18, 25, 26, 30, 35]\n",
    "\n",
    "with mlflow.start_run(experiment_id=hpt_experiment_id, run_name=cb_run_name):\n",
    "    objective = Objective(\n",
    "        run_name=cb_run_name,\n",
    "        experiment_id=hpt_experiment_id,\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_valid=X_valid,\n",
    "        y_valid=y_valid,\n",
    "        indexes=cb_features_indexes\n",
    "    )\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if credentials_config[\"EC2\"] != \"YOUR_S3_BUCKET_URL\":\n",
    "    # removing downloaded dataset from local\n",
    "    os.remove(PROCESSED_RAW_FILE_PATH)\n",
    "\n",
    "    # removing the local artifacts and features\n",
    "    shutil.rmtree(ARTIFACTS_OUTPUT_PATH)\n",
    "    shutil.rmtree(FEATURES_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registering Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"100d86e2471240dbb4b2199533bf6a55\"\n",
    "run_name = \"lightgbm_experiment_5\"\n",
    "name = \"lightgbm\"\n",
    "tags = {\"version\": \"1.0\", \"type\": \"baseline\", \"model\": name}\n",
    "\n",
    "result = mlflow.register_model(\n",
    "    model_uri=f\"runs:/{run_id}/{run_name}\",\n",
    "    name=name,\n",
    "    tags=tags,\n",
    "    await_registration_for=150,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e2e",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
