{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from mlflow.models import infer_signature\n",
    "from pprint import pprint\n",
    "from typing import Union, Dict, List, Tuple\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import boto3\n",
    "import joblib\n",
    "import os\n",
    "import math\n",
    "import mlflow\n",
    "import optuna\n",
    "import warnings\n",
    "import shutil\n",
    "import ast\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Get the current datetime string for experiment names\n",
    "current_datetime = datetime.now()\n",
    "datetime_string = current_datetime.strftime(\"%Y-%m-%d_%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_yaml_file(path, file):\n",
    "    # reading credentials files\n",
    "    with open(f\"{os.path.join(path, file)}\") as f:\n",
    "        try:\n",
    "            content = yaml.safe_load(f)\n",
    "        except yaml.YAMLError as e:\n",
    "            raise e\n",
    "\n",
    "    return content\n",
    "\n",
    "\n",
    "CONFIG_PATH = os.path.join(\"src\", \"config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials_config = read_yaml_file(path=CONFIG_PATH, file=\"credentials.yaml\")\n",
    "\n",
    "general_settings = read_yaml_file(path=CONFIG_PATH, file=\"settings.yaml\")\n",
    "\n",
    "if credentials_config[\"EC2\"] != \"YOUR_EC2_INSTANCE_URL\":\n",
    "    mlflow.set_tracking_uri(f\"http://{credentials_config['EC2']}:5000\")\n",
    "else:\n",
    "    mlflow.set_tracking_uri(f\"http://mlflow:5000\")\n",
    "\n",
    "print(f\"Tracking Server URI: '{mlflow.get_tracking_uri()}'\")\n",
    "\n",
    "SEED = 42\n",
    "ARTIFACTS_OUTPUT_PATH = general_settings[\"ARTIFACTS_PATH\"]\n",
    "FEATURES_OUTPUT_PATH = general_settings[\"FEATURES_PATH\"]\n",
    "RAW_FILE_PATH = os.path.join(\n",
    "    general_settings[\"DATA_PATH\"], general_settings[\"RAW_FILE_NAME\"]\n",
    ")\n",
    "PROCESSED_RAW_FILE = \"Preprocessed_\" + general_settings[\"RAW_FILE_NAME\"]\n",
    "PROCESSED_RAW_FILE_PATH = os.path.join(\n",
    "    general_settings[\"DATA_PATH\"], PROCESSED_RAW_FILE\n",
    ")\n",
    "FEATURE_SELECTION_EXPERIMENT_NAME = f\"feature-selection-experimentation\"\n",
    "HYPERPARAMETER_TUNING_EXPERIMENT_NAME = f\"hyperparameters-tuning-experimentation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading the preprocessed dataset from the aws s3 bucket\n",
    "if credentials_config[\"S3\"] != \"YOUR_S3_BUCKET_URL\":\n",
    "    # configuring AWS credentials\n",
    "    os.environ[\"AWS_ACCESS_KEY_ID\"] = credentials_config[\"AWS_ACCESS_KEY\"]\n",
    "    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = credentials_config[\"AWS_SECRET_KEY\"]\n",
    "\n",
    "    # downloading preprocessed dataset\n",
    "    s3 = boto3.client(\n",
    "        \"s3\",\n",
    "        aws_access_key_id=credentials_config[\"AWS_ACCESS_KEY\"],\n",
    "        aws_secret_access_key=credentials_config[\"AWS_SECRET_KEY\"]\n",
    "    )\n",
    "    s3.download_file(\n",
    "        credentials_config[\"S3\"],\n",
    "        PROCESSED_RAW_FILE,\n",
    "        PROCESSED_RAW_FILE_PATH\n",
    "    )\n",
    "\n",
    "    # downloading artifacts from the aws s3 bucket\n",
    "    !aws s3 cp --recursive s3://{credentials_config[\"S3\"]}/artifacts {ARTIFACTS_OUTPUT_PATH}\n",
    "\n",
    "    # downloading models from the aws s3 bucket\n",
    "    !aws s3 cp --recursive s3://{credentials_config[\"S3\"]}/features {FEATURES_OUTPUT_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading features\n",
    "X_train = joblib.load(os.path.join(FEATURES_OUTPUT_PATH, \"X_train.pkl\"))\n",
    "y_train = joblib.load(os.path.join(FEATURES_OUTPUT_PATH, \"y_train.pkl\"))\n",
    "\n",
    "X_valid = joblib.load(os.path.join(FEATURES_OUTPUT_PATH, \"X_valid.pkl\"))\n",
    "y_valid = joblib.load(os.path.join(FEATURES_OUTPUT_PATH, \"y_valid.pkl\"))\n",
    "\n",
    "# loading artifacts\n",
    "sc = joblib.load(os.path.join(ARTIFACTS_OUTPUT_PATH, \"features_sc.pkl\"))\n",
    "ohe = joblib.load(os.path.join(ARTIFACTS_OUTPUT_PATH, \"features_ohe.pkl\"))\n",
    "ohe_label = joblib.load(os.path.join(ARTIFACTS_OUTPUT_PATH, \"label_ohe.pkl\"))\n",
    "\n",
    "# loading feature columns\n",
    "temp_df = pd.read_csv(PROCESSED_RAW_FILE_PATH, sep=\",\")\n",
    "FEATURES_NAME = temp_df.columns.tolist()\n",
    "del temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REMOVE THIS CELL IN ACTUAL EXECUTIONS\n",
    "this is to make execution faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:1000, :10]\n",
    "y_train = y_train[:1000]\n",
    "X_valid = X_valid[:200, :10]\n",
    "y_valid = y_valid[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the baseline models\n",
    "dt = DecisionTreeClassifier(random_state=SEED)\n",
    "rf = RandomForestClassifier(random_state=SEED, verbose=0, n_jobs=-1)\n",
    "xg = XGBClassifier(random_state=SEED, n_jobs=-1)\n",
    "lg = LGBMClassifier(random_state=SEED, verbose=-1, objective=\"multiclass\")\n",
    "cb = CatBoostClassifier(random_seed=SEED, verbose=0, allow_writing_files=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_feature_selection(\n",
    "    model: Union[\n",
    "        DecisionTreeClassifier,\n",
    "        RandomForestClassifier,\n",
    "        XGBClassifier,\n",
    "        LGBMClassifier,\n",
    "        CatBoostClassifier,\n",
    "    ],\n",
    "    number_features: int,\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.array,\n",
    "    X_valid: np.ndarray,\n",
    "    y_valid: np.array,\n",
    ") -> Dict:\n",
    "    # initializing and fitting the sfs class\n",
    "    sfs = SequentialFeatureSelector(model, n_features_to_select=number_features, cv=3)\n",
    "    sfs.fit(X=X_train, y=y_train)\n",
    "\n",
    "    # getting the indexes of the best features\n",
    "    selected_features_indexes = np.argwhere(sfs.get_support()).reshape(-1)\n",
    "\n",
    "    reduced_X_train = sfs.transform(X_train)\n",
    "    reduced_X_valid = sfs.transform(X_valid)\n",
    "\n",
    "    # training the model\n",
    "    model.fit(reduced_X_train, y_train)\n",
    "\n",
    "    # calculating the training f1 score\n",
    "    predicted_y_train = model.predict(reduced_X_train)\n",
    "    train_f1 = f1_score(y_true=y_train, y_pred=predicted_y_train, average=\"weighted\")\n",
    "\n",
    "    # calculating the validation f1 score\n",
    "    predicted_y_valid = model.predict(reduced_X_valid)\n",
    "    valid_f1 = f1_score(y_true=y_valid, y_pred=predicted_y_valid, average=\"weighted\")\n",
    "\n",
    "    # inferring the signature of the trained model\n",
    "    signature = infer_signature(\n",
    "        model_input=reduced_X_train, model_output=predicted_y_train\n",
    "    )\n",
    "\n",
    "    # saving the metrics and artifacts that we want to log in mlflow\n",
    "    selected_features_names = list(\n",
    "        map(lambda i: FEATURES_NAME[i], selected_features_indexes.tolist())\n",
    "    )\n",
    "\n",
    "    results = {\n",
    "        \"train_f1\": train_f1,\n",
    "        \"valid_f1\": valid_f1,\n",
    "        \"features\": selected_features_names,\n",
    "        \"model\": model,\n",
    "        \"model_signature\": signature,\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def set_configurations_mlflow(\n",
    "    model: Union[\n",
    "        DecisionTreeClassifier,\n",
    "        RandomForestClassifier,\n",
    "        XGBClassifier,\n",
    "        LGBMClassifier,\n",
    "        CatBoostClassifier,\n",
    "    ],\n",
    "    y_train: np.array,\n",
    "    y_valid: np.array,\n",
    ") -> Tuple[np.array, np.array, str, str]:\n",
    "    # reshaping the target values (if needed) and setting the run name and which\n",
    "    # flavor is being used for each machine learning model\n",
    "    if isinstance(model, DecisionTreeClassifier):\n",
    "        y_train = np.argmax(y_train, axis=1)\n",
    "        y_valid = np.argmax(y_valid, axis=1)\n",
    "        run_name = \"decision_tree\"\n",
    "        flavor = \"sklearn\"\n",
    "\n",
    "    if isinstance(model, RandomForestClassifier):\n",
    "        run_name = \"random_forest\"\n",
    "        flavor = \"sklearn\"\n",
    "\n",
    "    if isinstance(model, XGBClassifier):\n",
    "        run_name = \"xgboost\"\n",
    "        flavor = \"xgboost\"\n",
    "\n",
    "    if isinstance(model, LGBMClassifier):\n",
    "        y_train = np.argmax(y_train, axis=1)\n",
    "        y_valid = np.argmax(y_valid, axis=1)\n",
    "        run_name = \"lightgbm\"\n",
    "        flavor = \"lightgbm\"\n",
    "\n",
    "    if isinstance(model, CatBoostClassifier):\n",
    "        y_train = np.argmax(y_train, axis=1)\n",
    "        y_valid = np.argmax(y_valid, axis=1)\n",
    "        run_name = \"catboost\"\n",
    "        flavor = \"catboost\"\n",
    "\n",
    "    # disabling some options of the current flavor's autolog\n",
    "    if flavor == \"sklearn\":\n",
    "        mlflow.sklearn.autolog(\n",
    "            log_models=False,\n",
    "            log_post_training_metrics=False,\n",
    "            log_model_signatures=False,\n",
    "            log_input_examples=True,\n",
    "            log_datasets=False,\n",
    "            silent=True,\n",
    "            disable=True,\n",
    "        )\n",
    "    elif flavor == \"xgboost\":\n",
    "        mlflow.xgboost.autolog(\n",
    "            log_models=False,\n",
    "            log_model_signatures=False,\n",
    "            log_input_examples=True,\n",
    "            log_datasets=False,\n",
    "            silent=True,\n",
    "            disable=True,\n",
    "        )\n",
    "    elif flavor == \"lightgbm\":\n",
    "        mlflow.lightgbm.autolog(\n",
    "            log_models=False,\n",
    "            log_model_signatures=False,\n",
    "            log_input_examples=True,\n",
    "            log_datasets=False,\n",
    "            silent=True,\n",
    "            disable=True,\n",
    "        )\n",
    "    elif flavor == \"catboost\":\n",
    "        # there is no autolog implemented for catboost\n",
    "        pass\n",
    "\n",
    "    return y_train, y_valid, run_name, flavor\n",
    "\n",
    "\n",
    "def run_feature_selection_experiment(\n",
    "    models: List,\n",
    "    min_features: int,\n",
    "    max_features: int,\n",
    "    experiment_id: str,\n",
    "    metric_to_optimize: str = \"valid_f1\",\n",
    "    direction: str = \"max\",\n",
    ") -> None:\n",
    "    for model in models:\n",
    "        # reshaping the target values (if needed) and setting some mlflow's configuration\n",
    "        new_y_train, new_y_valid, run_name, flavor = set_configurations_mlflow(\n",
    "            model=model, y_train=y_train, y_valid=y_valid\n",
    "        )\n",
    "        model_type_results = []\n",
    "\n",
    "        # starting a new run for the current model\n",
    "        with mlflow.start_run(experiment_id=experiment_id, run_name=run_name):\n",
    "            pprint(f\"Starting the run for the {run_name} model!\\n\")\n",
    "\n",
    "            for i, n_features in enumerate(range(min_features, max_features + 1)):\n",
    "                # creating a nested run inside the model's main run\n",
    "                with mlflow.start_run(\n",
    "                    experiment_id=experiment_id,\n",
    "                    run_name=f\"{run_name}_experiment_{i}\",\n",
    "                    nested=True,\n",
    "                ) as run:\n",
    "                    # running the feature selection main function\n",
    "                    results = apply_feature_selection(\n",
    "                        model=model,\n",
    "                        number_features=n_features,\n",
    "                        X_train=X_train,\n",
    "                        y_train=new_y_train,\n",
    "                        X_valid=X_valid,\n",
    "                        y_valid=new_y_valid,\n",
    "                    )\n",
    "\n",
    "                    # logging the trained model\n",
    "                    if flavor == \"sklearn\":\n",
    "                        mlflow.sklearn.log_model(\n",
    "                            results[\"model\"],\n",
    "                            run_name,\n",
    "                            signature=results[\"model_signature\"],\n",
    "                        )\n",
    "                        # logging the model\"s default parameters\n",
    "                        mlflow.log_params(results[\"model\"].get_params(deep=True))\n",
    "                    elif flavor == \"xgboost\":\n",
    "                        mlflow.xgboost.log_model(\n",
    "                            results[\"model\"],\n",
    "                            run_name,\n",
    "                            signature=results[\"model_signature\"],\n",
    "                        )\n",
    "                        # logging the model's default parameters\n",
    "                        mlflow.log_params(results[\"model\"].get_params(deep=True))\n",
    "                    elif flavor == \"lightgbm\":\n",
    "                        mlflow.lightgbm.log_model(\n",
    "                            results[\"model\"],\n",
    "                            run_name,\n",
    "                            signature=results[\"model_signature\"],\n",
    "                        )\n",
    "                        # logging the model's default parameters\n",
    "                        mlflow.log_params(results[\"model\"].get_params())\n",
    "                    elif flavor == \"catboost\":\n",
    "                        mlflow.catboost.log_model(\n",
    "                            results[\"model\"],\n",
    "                            run_name,\n",
    "                            signature=results[\"model_signature\"],\n",
    "                        )\n",
    "                        # logging the model's default parameters\n",
    "                        mlflow.log_params(results[\"model\"].get_all_params())\n",
    "\n",
    "                    # logging the training and validation scores\n",
    "                    mlflow.log_metric(\"train_f1\", results[\"train_f1\"])\n",
    "                    mlflow.log_metric(\"valid_f1\", results[\"valid_f1\"])\n",
    "\n",
    "                    # logging the artifacts (original dataset, features, and encoders objects)\n",
    "                    mlflow.log_artifact(PROCESSED_RAW_FILE_PATH)\n",
    "                    mlflow.log_artifact(ARTIFACTS_OUTPUT_PATH)\n",
    "                    mlflow.log_artifact(FEATURES_OUTPUT_PATH)\n",
    "\n",
    "                    # logging the indexes of the best features\n",
    "                    mlflow.log_param(\"features\", results[\"features\"])\n",
    "\n",
    "                    # add mlflow ids to results object and append to list\n",
    "                    results[\"experiment_id\"] = experiment_id\n",
    "                    results[\"run_name\"] = f\"{run_name}_experiment_{i}\"\n",
    "                    results[\"flavor\"] = flavor\n",
    "                    results[\"run_id\"] = run.info.run_id\n",
    "                    model_type_results.append(results)\n",
    "\n",
    "        # register the best feature selection in mlflow\n",
    "        df = pd.DataFrame.from_records(model_type_results)\n",
    "        if direction == \"min\":\n",
    "            best_result = df.loc[df[metric_to_optimize].idxmin()]\n",
    "        elif direction == \"max\":\n",
    "            best_result = df.loc[df[metric_to_optimize].idxmax()]\n",
    "        else:\n",
    "            raise NotImplementedError(\"\")\n",
    "        tags = {\"type\": \"baseline\", \"model\": run_name}\n",
    "        result = mlflow.register_model(\n",
    "            model_uri=f\"runs:/{best_result['run_id']}/{best_result['run_name']}\",\n",
    "            name=f\"{FEATURE_SELECTION_EXPERIMENT_NAME}_{run_name}\",\n",
    "            tags=tags,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [dt, rf, xg, lg, cb]\n",
    "min_features = math.floor(X_train.shape[1] * 0.2)\n",
    "max_features = math.floor(X_train.shape[1] * 0.5)\n",
    "\n",
    "# creating a new mlflow's experiment\n",
    "experiment_id = mlflow.create_experiment(\n",
    "    name=FEATURE_SELECTION_EXPERIMENT_NAME + \"_\" + datetime_string,\n",
    ")\n",
    "\n",
    "# running the feature selection experiments\n",
    "run_feature_selection_experiment(\n",
    "    models=models,\n",
    "    min_features=min_features,\n",
    "    max_features=max_features,\n",
    "    experiment_id=experiment_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Objective:\n",
    "    def __init__(\n",
    "        self,\n",
    "        run_group_name: str,\n",
    "        experiment_id: str,\n",
    "        X_train: np.ndarray,\n",
    "        y_train: np.array,\n",
    "        X_valid: np.ndarray,\n",
    "        y_valid: np.array,\n",
    "        indexes: List,\n",
    "    ) -> None:\n",
    "        self.run_group_name = run_group_name\n",
    "        self.experiment_id = experiment_id\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_valid = X_valid\n",
    "        self.y_valid = y_valid\n",
    "        self.indexes_name = indexes\n",
    "        self.indexes = [FEATURES_NAME.index(i) for i in indexes]\n",
    "\n",
    "        if self.run_group_name in [\"decision_tree\", \"lightgbm\", \"catboost\"]:\n",
    "            self.y_train = np.argmax(self.y_train, axis=1)\n",
    "            self.y_valid = np.argmax(self.y_valid, axis=1)\n",
    "\n",
    "        self.X_train = self.X_train[:, self.indexes]\n",
    "        self.X_valid = self.X_valid[:, self.indexes]\n",
    "\n",
    "    def __call__(self, trial: optuna.trial.Trial) -> float:\n",
    "        with mlflow.start_run(\n",
    "            experiment_id=self.experiment_id,\n",
    "            run_name=f\"{self.run_group_name}_trial_{trial.number}\",\n",
    "            nested=True,\n",
    "        ) as run:\n",
    "            trial.set_user_attr(\"run_id\", run.info.run_id)\n",
    "            trial.set_user_attr(\"run_name\", run.info.run_name)\n",
    "            if self.run_group_name == \"decision_tree\":\n",
    "                params = {\n",
    "                    \"max_depth\": trial.suggest_int(\"max_depth\", 2, 32, step=2),\n",
    "                    \"min_samples_split\": trial.suggest_int(\n",
    "                        \"min_samples_split\", 2, 8, step=1\n",
    "                    ),\n",
    "                    \"min_samples_leaf\": trial.suggest_int(\n",
    "                        \"min_samples_leaf\", 1, 6, step=1\n",
    "                    ),\n",
    "                    \"min_weight_fraction_leaf\": trial.suggest_float(\n",
    "                        \"min_weight_fraction_leaf\", 0, 0.5, step=0.1\n",
    "                    ),\n",
    "                    \"max_leaf_nodes\": trial.suggest_int(\n",
    "                        \"max_leaf_nodes\", 2, 16, step=2\n",
    "                    ),\n",
    "                    \"random_state\": SEED,\n",
    "                }\n",
    "                model = DecisionTreeClassifier(**params)\n",
    "\n",
    "            if self.run_group_name == \"random_forest\":\n",
    "                params = {\n",
    "                    \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "                    \"max_depth\": trial.suggest_int(\"max_depth\", 10, 50),\n",
    "                    \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 32),\n",
    "                    \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 32),\n",
    "                    \"random_state\": SEED,\n",
    "                    \"n_jobs\": -1,\n",
    "                }\n",
    "                model = RandomForestClassifier(**params)\n",
    "\n",
    "            if self.run_group_name == \"xgboost\":\n",
    "                params = {\n",
    "                    \"booster\": trial.suggest_categorical(\n",
    "                        \"booster\", [\"gbtree\", \"gblinear\", \"dart\"]\n",
    "                    ),\n",
    "                    \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
    "                    \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
    "                    \"random_state\": SEED,\n",
    "                    \"n_jobs\": -1,\n",
    "                }\n",
    "                model = XGBClassifier(**params)\n",
    "\n",
    "            if self.run_group_name == \"lightgbm\":\n",
    "                params = {\n",
    "                    \"objective\": \"multiclass\",\n",
    "                    \"verbosity\": -1,\n",
    "                    \"random_state\": SEED,\n",
    "                    \"n_jobs\": -1,\n",
    "                    \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "                    \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "                    \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "                    \"feature_fraction\": trial.suggest_float(\n",
    "                        \"feature_fraction\", 0.4, 1.0\n",
    "                    ),\n",
    "                    \"bagging_fraction\": trial.suggest_float(\n",
    "                        \"bagging_fraction\", 0.4, 1.0\n",
    "                    ),\n",
    "                    \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "                    \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "                }\n",
    "                model = LGBMClassifier(**params)\n",
    "\n",
    "            if self.run_group_name == \"catboost\":\n",
    "                params = {\n",
    "                    \"random_seed\": SEED,\n",
    "                    \"verbose\": 0,\n",
    "                    \"allow_writing_files\": False,\n",
    "                    \"colsample_bylevel\": trial.suggest_float(\n",
    "                        \"colsample_bylevel\", 0.01, 0.1\n",
    "                    ),\n",
    "                    \"depth\": trial.suggest_int(\"depth\", 1, 12),\n",
    "                    \"boosting_type\": trial.suggest_categorical(\n",
    "                        \"boosting_type\", [\"Ordered\", \"Plain\"]\n",
    "                    ),\n",
    "                    \"bootstrap_type\": trial.suggest_categorical(\n",
    "                        \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]\n",
    "                    ),\n",
    "                }\n",
    "                model = CatBoostClassifier(**params)\n",
    "\n",
    "            model.fit(X=self.X_train, y=self.y_train)\n",
    "\n",
    "            # calculating the training f1 score\n",
    "            train_prediction = model.predict(self.X_train)\n",
    "            train_f1 = f1_score(\n",
    "                y_true=self.y_train, y_pred=train_prediction, average=\"weighted\"\n",
    "            )\n",
    "\n",
    "            # calculating the validation f1 score\n",
    "            valid_prediction = model.predict(self.X_valid)\n",
    "            valid_f1 = f1_score(\n",
    "                y_true=self.y_valid, y_pred=valid_prediction, average=\"weighted\"\n",
    "            )\n",
    "\n",
    "            # logging the training and validation scores\n",
    "            mlflow.log_metric(\"train_f1\", train_f1)\n",
    "            mlflow.log_metric(\"valid_f1\", valid_f1)\n",
    "\n",
    "            # inferring the signature of the trained model\n",
    "            signature = infer_signature(\n",
    "                model_input=self.X_train, model_output=train_prediction\n",
    "            )\n",
    "\n",
    "            # saving the trained model\n",
    "            if self.run_group_name in [\"decision_tree\", \"random_forest\"]:\n",
    "                # sklearn flavor\n",
    "                mlflow.sklearn.log_model(\n",
    "                    model, self.run_group_name, signature=signature\n",
    "                )\n",
    "                # logging the model\"s default parameters\n",
    "                mlflow.log_params(model.get_params(deep=True))\n",
    "            elif self.run_group_name == \"xgboost\":\n",
    "                mlflow.xgboost.log_model(\n",
    "                    model, self.run_group_name, signature=signature\n",
    "                )\n",
    "                # logging the model's default parameters\n",
    "                mlflow.log_params(model.get_params())\n",
    "            elif self.run_group_name == \"lightgbm\":\n",
    "                mlflow.lightgbm.log_model(\n",
    "                    model, self.run_group_name, signature=signature\n",
    "                )\n",
    "                # logging the model's default parameters\n",
    "                mlflow.log_params(model.get_params())\n",
    "            elif self.run_group_name == \"catboost\":\n",
    "                mlflow.catboost.log_model(\n",
    "                    model, self.run_group_name, signature=signature\n",
    "                )\n",
    "                # logging the model's default parameters\n",
    "                mlflow.log_params(model.get_all_params())\n",
    "\n",
    "        return valid_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new mlflow's experiment\n",
    "hpt_experiment_id = mlflow.create_experiment(\n",
    "    name=HYPERPARAMETER_TUNING_EXPERIMENT_NAME + \"_\" + datetime_string,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run optuna trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_model_params(model_name):\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    latest_version_info = client.get_latest_versions(model_name)[0]\n",
    "    run_id = latest_version_info.run_id\n",
    "    run = client.get_run(run_id)\n",
    "\n",
    "    # Get the parameters logged for the run\n",
    "    parameters = run.data.params\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def run_mlflow_experiment(run_group_name, experiment_id, direction=\"maximize\"):\n",
    "    dt_run_params = get_latest_model_params(\n",
    "        FEATURE_SELECTION_EXPERIMENT_NAME + \"_\" + run_group_name\n",
    "    )\n",
    "    dt_features_indexes = ast.literal_eval(dt_run_params[\"features\"])\n",
    "\n",
    "    with mlflow.start_run(experiment_id=experiment_id, run_name=run_group_name):\n",
    "        objective = Objective(\n",
    "            run_group_name=run_group_name,\n",
    "            experiment_id=experiment_id,\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            X_valid=X_valid,\n",
    "            y_valid=y_valid,\n",
    "            indexes=dt_features_indexes,\n",
    "        )\n",
    "\n",
    "        study = optuna.create_study(direction=direction)\n",
    "        study.optimize(objective, n_trials=10)\n",
    "\n",
    "        return study.trials_dataframe()\n",
    "\n",
    "\n",
    "all_trials_dfs = []\n",
    "run_group_names = [\"decision_tree\", \"random_forest\", \"xgboost\", \"lightgbm\", \"catboost\"]\n",
    "for run_group_name in run_group_names:\n",
    "    trials_df = run_mlflow_experiment(\n",
    "        run_group_name, experiment_id, direction=\"maximize\"\n",
    "    )\n",
    "    all_trials_dfs.append(trials_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze all trial results, and register best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trials = pd.concat(all_trials_dfs, axis=0)\n",
    "best_trial_id = df_trials[\"value\"].idxmax()\n",
    "best_trial = df_trials.iloc[best_trial_id]\n",
    "\n",
    "results = mlflow.register_model(\n",
    "    model_uri=f\"runs:/{best_trial['user_attrs_run_id']}/{best_trial['user_attrs_run_name']}\",\n",
    "    name=f\"experimentation-best-model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if credentials_config[\"EC2\"] != \"YOUR_EC2_INSTANCE_URL\":\n",
    "    # removing downloaded dataset from local\n",
    "    os.remove(PROCESSED_RAW_FILE_PATH)\n",
    "\n",
    "    # removing the local artifacts and features\n",
    "    shutil.rmtree(ARTIFACTS_OUTPUT_PATH)\n",
    "    shutil.rmtree(FEATURES_OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
